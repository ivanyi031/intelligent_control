# -*- coding: utf-8 -*-
"""「HW5-2 epoch=50(2)」的副本

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MMDYjN3mpTh2o-0cLxcAvdYyUYNhBFub

# 1. Import Library
"""

from tensorflow import keras
from keras.datasets import cifar10
import numpy as np
np.random.seed(10)

"""# 資料準備"""

(x_img_train,y_label_train),(x_img_test,y_label_test)=cifar10.load_data()

"""自動下載data set"""

print("train data:",'images:',x_img_train.shape,
      " labels:",y_label_train.shape) 
print("test  data:",'images:',x_img_test.shape ,
      " labels:",y_label_test.shape)

"""順序標記訓練集和測試集的(資料數量,形狀和通道數量)
例:(50000筆,像素32*32,RGB圖片通道為3)
"""

x_img_train_normalize = x_img_train.astype('float32') / 255.0
x_img_test_normalize = x_img_test.astype('float32') / 255.0

"""因為圖片像素數據以0到255表達，因此將數據(圖片)除以255,進行標準化,提高準確率"""

from keras.utils import np_utils
y_label_train_OneHot = np_utils.to_categorical(y_label_train)
y_label_test_OneHot = np_utils.to_categorical(y_label_test)

"""將圖片預先做好的標籤欄位轉換為Onehot encoding,方便後續繪制圖表時直接代入標籤文字"""

y_label_test_OneHot.shape

"""執行結果,數量為被處理的圖片數量

# 建立模型
"""

from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D

model = Sequential()

"""建立一個Sequential線性堆疊模型,往下便可以直接順序加入模型"""

#卷積層1

model.add(Conv2D(filters=128,kernel_size=(3,3),
                 input_shape=(32,32,3), 
                 activation='relu', 
                 padding='same'))
model.add(Conv2D(filters=128,kernel_size=(3,3),
                 input_shape=(32,32,3), 
                 activation='relu', 
                 padding='same'))

"""filters:隨機產生32個濾鏡filters weight

kernel size(3,3):每一個濾鏡3*3大小

input shape:輸入圖像格式,Cifar資料集像素為32*32,RGB的三原色通道為3

activation:使用relu激活函數

padding:設定讓卷積運算後的影像大小不變
"""

model.add(Dropout(rate=0.3))

"""每次訓練迭代會隨機放棄神經網路中的25%神經元,避免overfitting"""

model.add(MaxPooling2D(pool_size=(2, 2)))

"""建立池化層,(2,2)的意思為將(32,32)除以(2,2),把影像縮小為(16,16),但是數量仍保持32個"""

#卷積層2與池化層2

model.add(Conv2D(filters=128, kernel_size=(3, 3), 
                 activation='relu', padding='same'))
model.add(Conv2D(filters=128, kernel_size=(3, 3), 
                 activation='relu', padding='same'))

model.add(Dropout(0.3))

model.add(MaxPooling2D(pool_size=(2, 2)))

"""卷積層3 與池化層3

"""

model.add(Conv2D(filters=128, kernel_size=(3, 3), 
                 activation='relu', padding='same'))
model.add(Conv2D(filters=128, kernel_size=(3, 3), 
                 activation='relu', padding='same'))

model.add(Dropout(0.3))

model.add(MaxPooling2D(pool_size=(2, 2)))

"""卷積層4與池化層4"""

model.add(Conv2D(filters=256, kernel_size=(3, 3), 
                 activation='relu', padding='same'))

model.add(Conv2D(filters=256, kernel_size=(3, 3), 
                 activation='relu', padding='same'))
model.add(Dropout(0.3))
model.add(MaxPooling2D(pool_size=(2, 2)))

#Step3	建立神經網路(平坦層、隱藏層、輸出層)

model.add(Flatten())

"""建立平坦層,8x8x64=4096,剛好等於上一個池化層的神經元數量,

並在每次訓練迭代放棄25%的神經元
"""

model.add(Dense(1024,activation='relu'))

model.add(Dense(1024, activation='relu'))
model.add(Dropout(rate=0.3))

"""建立隱藏層,共1024個神經元"""

model.add(Dense(10, activation='softmax'))

"""建立輸出層,共10個神經元,對應10個影像分類,使用softmax激活函數進行轉換,

讓結果轉換成預測每一個影像的機率
"""

print(model.summary())

"""# 載入之前訓練的模型"""

try:
    model.load_weights("SaveModel/cifarCnnModelnew1.h5")
    print("載入模型成功!繼續訓練模型")
except :    
    print("載入模型失敗!開始訓練一個新模型")

opt =keras.optimizers.Adam(learning_rate=0.001)

"""# 訓練模型"""

model.compile(loss='categorical_crossentropy',
              optimizer=opt, metrics=['accuracy'])

"""設定損失函數,在深度學習中通常會使用cross entropy交叉熵,訓練效果較好"""

train_history=model.fit(x_img_train_normalize, y_label_train_OneHot,
                        validation_split=0.2,
                        epochs=50, batch_size=128, verbose=1)

"""輸入圖像標籤文字

validatiom split:訓練集和測試集的比例,這次為50000:10000,所以是0.2

epochs:訓練週期10次

batch size:每批次輸入128張圖片
"""

import matplotlib.pyplot as plt
def show_train_history(train_acc,test_acc):
    plt.plot(train_history.history[train_acc])
    plt.plot(train_history.history[test_acc])
    plt.title('Train History')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()

"""設定圖表欄位和格式"""

show_train_history('accuracy','val_accuracy')

"""accuracy:訓練時的準確率

val accuracy:驗證時的準確率
"""

show_train_history('loss','val_loss')

"""loss:訓練時的誤差

val accuracy:驗證時的誤差

# 評估模型準確率
"""

scores = model.evaluate(x_img_test_normalize, 
                        y_label_test_OneHot, verbose=0)
scores[1]

"""# 進行預測"""

prediction=np.argmax(model.predict(x_img_test_normalize), axis=-1)

prediction[:10]

"""# 查看預測結果"""

label_dict={0:"airplane",1:"automobile",2:"bird",3:"cat",4:"deer",
            5:"dog",6:"frog",7:"horse",8:"ship",9:"truck"}

import matplotlib.pyplot as plt
def plot_images_labels_prediction(images,labels,prediction,
                                  idx,num=10):
    fig = plt.gcf()
    fig.set_size_inches(12, 14)
    if num>25: num=25 
    for i in range(0, num):
        ax=plt.subplot(5,5, 1+i)
        ax.imshow(images[idx],cmap='binary')
                
        title=str(i)+','+label_dict[labels[i][0]]
        if len(prediction)>0:
            title+='=>'+label_dict[prediction[i]]
            
        ax.set_title(title,fontsize=10) 
        ax.set_xticks([]);ax.set_yticks([])        
        idx+=1 
    plt.show()

plot_images_labels_prediction(x_img_test,y_label_test,
                              prediction,0,10)

"""# 查看預測機率"""

Predicted_Probability=model.predict(x_img_test_normalize)

def show_Predicted_Probability(y,prediction,
                               x_img,Predicted_Probability,i):
    print('label:',label_dict[y[i][0]],
          'predict:',label_dict[prediction[i]])
    plt.figure(figsize=(2,2))
    plt.imshow(np.reshape(x_img_test[i],(32, 32,3)))
    plt.show()
    for j in range(10):
        print(label_dict[j]+
              ' Probability:%1.9f'%(Predicted_Probability[i][j]))

show_Predicted_Probability(y_label_test,prediction,
                           x_img_test,Predicted_Probability,0)

show_Predicted_Probability(y_label_test,prediction,
                           x_img_test,Predicted_Probability,3)

"""# confusion matrix"""

prediction.shape

"""建立混淆矩陣時結果資據必須為1維陣列,如果括號有多於一筆數據,則必須先進行數據處理"""

y_label_test.shape

"""執行結果顯示已轉換為1維陣列"""

y_label_test

y_label_test.reshape(-1)

import pandas as pd
print(label_dict)
pd.crosstab(y_label_test.reshape(-1),prediction,
            rownames=['label'],colnames=['predict'])

"""匯入pandas模組

reshape(-1)轉換1維陣列

測試資料的預測結果

設定行的名稱label

設定列的名稱是predict
"""

print(label_dict)

"""# Save model to Google Drive"""

from google.colab import drive
drive.mount('/content/drive')

"""# Save model to JSON"""

model_json = model.to_json()
with open("/content/drive", "w") as json_file:
    json_file.write(model_json)

"""# Save Weight to h5 """

model.save_weights("/content/drive/MyDrive/Colab Notebooks/SaveModel/cifarCnnModelnew.h5")
print("Saved model to disk")